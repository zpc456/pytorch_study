{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98885608",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d932e235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "#      transforms.RandomHorizontalFlip(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./dataset/', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./dataset/', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "974fbe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = trainloader.__iter__().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d77ad0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8431a9fd00>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(a[0][0,...].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e5cd6",
   "metadata": {},
   "source": [
    "### Define Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ea964",
   "metadata": {},
   "source": [
    "torch.Size([4, 3, 32, 32])\n",
    "torch.Size([4, 6, 14, 14])\n",
    "torch.Size([4, 16, 5, 5])\n",
    "torch.Size([4, 400])\n",
    "torch.Size([4, 120])\n",
    "torch.Size([4, 84])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c725efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.conv3 = nn.Conv2d(20, 50, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(50 * 5 * 5, 600)\n",
    "        self.fc2 = nn.Linear(600, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        x = self.pool(F.relu(self.conv1(x)))#[10, 14, 14]\n",
    "#         print(x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))#[20, 5, 5]\n",
    "        x = F.relu(self.conv3(x))#[50, 5, 5]\n",
    "#         print(x.shape)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.fc2(x))\n",
    "#         print(x.shape)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955115d7",
   "metadata": {},
   "source": [
    "### Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fca48f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e0ee03",
   "metadata": {},
   "source": [
    "### Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09be9aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.416\n",
      "[1,  4000] loss: 1.366\n",
      "[1,  6000] loss: 1.329\n",
      "[1,  8000] loss: 1.288\n",
      "[1, 10000] loss: 1.283\n",
      "[1, 12000] loss: 1.235\n",
      "[2,  2000] loss: 1.184\n",
      "[2,  4000] loss: 1.163\n",
      "[2,  6000] loss: 1.131\n",
      "[2,  8000] loss: 1.148\n",
      "[2, 10000] loss: 1.136\n",
      "[2, 12000] loss: 1.102\n",
      "[3,  2000] loss: 1.037\n",
      "[3,  4000] loss: 1.031\n",
      "[3,  6000] loss: 1.039\n",
      "[3,  8000] loss: 1.031\n",
      "[3, 10000] loss: 1.050\n",
      "[3, 12000] loss: 1.018\n",
      "[4,  2000] loss: 0.948\n",
      "[4,  4000] loss: 0.950\n",
      "[4,  6000] loss: 0.959\n",
      "[4,  8000] loss: 0.956\n",
      "[4, 10000] loss: 0.949\n",
      "[4, 12000] loss: 0.942\n",
      "[5,  2000] loss: 0.874\n",
      "[5,  4000] loss: 0.874\n",
      "[5,  6000] loss: 0.882\n",
      "[5,  8000] loss: 0.869\n",
      "[5, 10000] loss: 0.877\n",
      "[5, 12000] loss: 0.876\n",
      "[6,  2000] loss: 0.815\n",
      "[6,  4000] loss: 0.817\n",
      "[6,  6000] loss: 0.804\n",
      "[6,  8000] loss: 0.828\n",
      "[6, 10000] loss: 0.806\n",
      "[6, 12000] loss: 0.833\n",
      "[7,  2000] loss: 0.749\n",
      "[7,  4000] loss: 0.754\n",
      "[7,  6000] loss: 0.749\n",
      "[7,  8000] loss: 0.763\n",
      "[7, 10000] loss: 0.795\n",
      "[7, 12000] loss: 0.790\n",
      "[8,  2000] loss: 0.686\n",
      "[8,  4000] loss: 0.716\n",
      "[8,  6000] loss: 0.721\n",
      "[8,  8000] loss: 0.728\n",
      "[8, 10000] loss: 0.717\n",
      "[8, 12000] loss: 0.752\n",
      "[9,  2000] loss: 0.646\n",
      "[9,  4000] loss: 0.673\n",
      "[9,  6000] loss: 0.683\n",
      "[9,  8000] loss: 0.700\n",
      "[9, 10000] loss: 0.683\n",
      "[9, 12000] loss: 0.691\n",
      "[10,  2000] loss: 0.601\n",
      "[10,  4000] loss: 0.615\n",
      "[10,  6000] loss: 0.627\n",
      "[10,  8000] loss: 0.653\n",
      "[10, 10000] loss: 0.661\n",
      "[10, 12000] loss: 0.673\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8762ae",
   "metadata": {},
   "source": [
    "### Test Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642fc457",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed95a712",
   "metadata": {},
   "source": [
    "|epoch|acc|\n",
    "|:----:|:----:|\n",
    "|1|49%|\n",
    "|2|54%|\n",
    "|20|59%|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733e1217",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "name": "conda-env-pytorch-py",
   "language": "python",
   "display_name": "Python [conda env:pytorch] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}